# ğŸ™ Ceph Master Guide: Nedir, Ne DeÄŸildir, NasÄ±l Ã‡alÄ±ÅŸÄ±r?

Bu dokÃ¼man, Ceph depolama sistemini en temelinden en derin mimarisine kadar, bir sistem mÃ¼hendisinin bilmesi gereken detaylarla anlatmak iÃ§in hazÄ±rlanmÄ±ÅŸtÄ±r. Kurulumdan Ã¶nce "Neye bulaÅŸÄ±yoruz?" sorusunun tam cevabÄ±dÄ±r.

---

## 1. Ceph Nedir?

Ceph; **aÃ§Ä±k kaynaklÄ±**, **daÄŸÄ±tÄ±k (distributed)** ve **yazÄ±lÄ±m tabanlÄ± (software-defined)** bir depolama platformudur.

En bÃ¼yÃ¼k Ã¶zelliÄŸi **"Unified Storage" (BÃ¼tÃ¼nleÅŸik Depolama)** olmasÄ±dÄ±r. Yani dÃ¼nyadaki Ã¼Ã§ ana depolama yÃ¶ntemini tek bir kÃ¼mede (cluster) sunabilir:

1. **Blok Depolama (Block Storage):** Sanal makineler (VM) ve diskler iÃ§in (AWS EBS veya SAN gibi).
2. **Nesne Depolama (Object Storage):** BÃ¼yÃ¼k, yapÄ±sal olmayan veriler iÃ§in (AWS S3 gibi).
3. **Dosya Sistemi (File System):** KlasÃ¶r paylaÅŸÄ±mÄ± ve POSIX uyumlu eriÅŸim iÃ§in (NAS/NFS gibi).

### Ceph Ne DeÄŸildir?

* **Basit bir NAS deÄŸildir:** Evdeki QNAP veya Synology gibi "tak-Ã§alÄ±ÅŸtÄ±r" bir cihaz deÄŸildir.
* **RAID kullanmaz:** Geleneksel donanÄ±m RAID kartlarÄ±na (RAID 5, RAID 10 vb.) ihtiyaÃ§ duymaz, hatta onlardan nefret eder. Kendi yazÄ±lÄ±msal korumasÄ±nÄ± kullanÄ±r.
* **Tek sunuculuk iÅŸ deÄŸildir:** En az 3 sunucu ile gerÃ§ek gÃ¼cÃ¼nÃ¼ gÃ¶sterir. Tek sunucuda Ã§alÄ±ÅŸÄ±r ama Ceph'in mantÄ±ÄŸÄ±na aykÄ±rÄ±dÄ±r.

---

## 2. TarihÃ§e ve Ekosistem

"Bu teknoloji kimin eseri?" diye merak ediyorsanÄ±z, iÅŸte kÄ±sa bir tarihÃ§e:

* **Kurucu:** Sage Weil.
* **DoÄŸuÅŸ Yeri:** University of California, Santa Cruz (UCSC). Sage Weil'in doktora tezi olarak baÅŸladÄ± (2003-2007).
* **Ä°lk SÃ¼rÃ¼m:** 2006'da aÃ§Ä±k kaynak (LGPL) olarak yayÄ±nlandÄ±.
* **ÅirketleÅŸme:** 2012'de Sage Weil, Ceph'i geliÅŸtirmek iÃ§in **Inktank** ÅŸirketini kurdu.
* **BÃ¼yÃ¼k SatÄ±n Almalar:**
  * 2014: **Red Hat**, Inktank'i 175 Milyon Dolar'a satÄ±n aldÄ±.
  * 2019: **IBM**, Red Hat'i satÄ±n alarak teknolojinin en bÃ¼yÃ¼k hamisi oldu.
* **Ä°smin KÃ¶keni:** "Cephalopod" (Ahtapot, mÃ¼rekkep balÄ±ÄŸÄ± sÄ±nÄ±fÄ±) kelimesinden gelir. DaÄŸÄ±tÄ±k kollarÄ± olan, merkezi olmayan yapÄ±yÄ± temsil eder. UCSC'nin maskotu "Sammy" (bir Banana Slug) ile karÄ±ÅŸtÄ±rÄ±lsa da, logo ahtapot temasÄ±nÄ± iÅŸler.

BugÃ¼n Linux Ã§ekirdeÄŸinin (Kernel) yerleÅŸik bir parÃ§asÄ±dÄ±r ve CERN, Cisco, Bloomberg gibi dev yapÄ±lar tarafÄ±ndan kullanÄ±lmaktadÄ±r.

---

## 3. Temel Mimari: RADOS ve CRUSH

Ceph'in kalbinde **RADOS** (Reliable Autonomic Distributed Object Store) yatar. Her ÅŸeyi bu yÃ¶netir. Ãœstteki Blok, Nesne ve Dosya servisleri aslÄ±nda RADOS'un mÃ¼ÅŸterileridir.

### ğŸ§  CRUSH AlgoritmasÄ± (Sihirli DeÄŸnek)

Geleneksel depolamada "Dosya A nerede?" diye sorulduÄŸunda, merkezi bir veritabanÄ±na (Metadata Server) bakÄ±lÄ±r. Bu darboÄŸaz yaratÄ±r.

Ceph ise **CRUSH** (Controlled Replication Under Scalable Hashing) algoritmasÄ±nÄ± kullanÄ±r.

* **MantÄ±k:** Verinin nerede duracaÄŸÄ±nÄ± **hesaplar**, "sormaz".
* Ä°stemci (Client) matematiksel bir iÅŸlem yapar ve "Bu dosya Node 3'teki Disk 5'e gitmeli" der.
* Bu sayede merkezi bir darboÄŸaz (bottleneck) olmadan Exabyte'larca veriyi yÃ¶netebilir.

---

## 4. Ceph BileÅŸenleri (Diksiyonu)

Bir Ceph kÃ¼mesi ÅŸu 5 temel parÃ§adan oluÅŸur:

### 1. OSD (Object Storage Daemon) - "Ä°ÅŸÃ§iler"

* **GÃ¶revi:** Veriyi diske yazan, okuyan, Ã§oÄŸaltan ve disk bozulursa iyileÅŸtiren (recovery) servistir.
* **Kural:** Genelde her fiziksel disk (HDD/SSD) iÃ§in 1 adet OSD servisi Ã§alÄ±ÅŸÄ±r. 10 diskin varsa 10 OSD'n vardÄ±r.

### 2. MON (Monitor) - "Beyin TakÄ±mÄ±"

* **GÃ¶revi:** KÃ¼menin haritasÄ±nÄ± (Cluster Map) tutar. Kim ayakta, kim Ã§Ã¶ktÃ¼, veri nerede olmalÄ±?
* **Kural:** Tek sayÄ± olmak zorundadÄ±r (1, 3, 5). "Quorum" (Oylama) usulÃ¼ Ã§alÄ±ÅŸÄ±r. Ã‡oÄŸunluk saÄŸlanamazsa (Split-Brain) sistemi kilitler.

### 3. MGR (Manager) - "Ä°statistikÃ§i"

* **GÃ¶revi:** Performans metriklerini toplar, Dashboard'u sunar ve orkestrasyonu saÄŸlar.
* **Kural:** En az 1 aktif, 1 yedek (standby) olmasÄ± Ã¶nerilir.

### 4. MDS (Metadata Server) - "KÃ¼tÃ¼phaneci"

* **GÃ¶revi:** *Sadece CephFS (Dosya sistemi)* kullanÄ±yorsan gereklidir. Dosya isimleri, izinler ve dizin yapÄ±sÄ±nÄ± tutar.
* **Not:** Blok ve Object storage iÃ§in MDS gerekmez.

### 5. RGW (Rados Gateway) - "TercÃ¼man"

* **GÃ¶revi:** HTTP isteklerini (S3 veya Swift API) Ceph'in anlayacaÄŸÄ± dile (RADOS) Ã§evirir. Object Storage kullanacaksan gereklidir.

---

## 5. Veri NasÄ±l Korunur? (Replica vs Erasure Coding)

Ceph, verilerinizi kaybetmemek iÃ§in iki yÃ¶ntem sunar:

### A. Replikasyon (VarsayÄ±lan)

* Verinin kopyasÄ±nÄ± farklÄ± sunuculara yazar.
* **Ã–rnek (Size=3):** 1 GB veri yazarsan, fiziksel olarak 3 GB yer kaplar.
* **AvantajÄ±:** Ã‡ok hÄ±zlÄ±dÄ±r, iyileÅŸme (recovery) sÃ¼resi kÄ±sadÄ±r.
* **DezavantajÄ±:** PahalÄ±dÄ±r (Disk alanÄ±nÄ±n 3'te 1'ini kullanÄ±rsÄ±n).

### B. Erasure Coding (EC)

* RAID 5 veya RAID 6'nÄ±n matematiksel karÅŸÄ±lÄ±ÄŸÄ±dÄ±r. Veriyi parÃ§alar ve parite (koruma) kodlarÄ± ekler.
* **Ã–rnek (4+2):** Veriyi 4 parÃ§aya bÃ¶l, 2 tane de koruma parÃ§asÄ± ekle. Toplam 6 parÃ§a farklÄ± yerlere daÄŸÄ±lÄ±r.
* **AvantajÄ±:** Verimlidir (Disk alanÄ±nÄ±n %66'sÄ±nÄ± kullanÄ±rsÄ±n).
* **DezavantajÄ±:** Yazma iÅŸlemi yavaÅŸtÄ±r (CPU kullanÄ±r), iyileÅŸme sÃ¼resi uzundur. Genelde arÅŸiv/yedekleme iÃ§in kullanÄ±lÄ±r.

---

## 6. Ceph Trafik AkÄ±ÅŸÄ± (Life of an I/O)

Bir dosya yazmak istediÄŸinde arka planda ÅŸunlar olur:

1. **Ä°stemci:** DosyayÄ± (Object) havuza (Pool) atmak ister.
2. **Hash:** Dosya isminin Hash'ini alÄ±r.
3. **PG (Placement Group):** Hash sonucuna gÃ¶re dosyanÄ±n hangi PG'ye (Sanal Kova) gireceÄŸini bulur.
4. **CRUSH HesaplamasÄ±:** "Bu PG ÅŸu an hangi OSD'lerde (Disklerde) durmalÄ±?" sorusunu CRUSH algoritmasÄ± ile hesaplar.
5. **Yazma:** Ä°stemci, birincil (Primary) OSD'ye veriyi yazar.
6. **Replikasyon:** Birincil OSD, veriyi alÄ±r ve diÄŸer 2 kopya OSD'ye (Secondary) gÃ¶nderir (varsayÄ±lan size=3 iÃ§in).
7. **Onay (Ack):** DiÄŸer 2 OSD "YazdÄ±m" dediÄŸinde, Birincil OSD istemciye "Ä°ÅŸlem Tamam" der.
    * *Bu sayede veri tutarlÄ±lÄ±ÄŸÄ± (consistency) %100 garanti altÄ±na alÄ±nÄ±r.*

---

## 7. KullanÄ±m SenaryolarÄ± ve Mimari YaklaÅŸÄ±m

Ceph'in gÃ¼cÃ¼, 3 farklÄ± depolama teknolojisini tek bir platformda sunmasÄ±ndan gelir. GerÃ§ek dÃ¼nyada bu teknolojiler ÅŸÃ¶yle kullanÄ±lÄ±r:

### ğŸ…°ï¸ 3 Temel Depolama TÃ¼rÃ¼ne GÃ¶re KullanÄ±m

| TÃ¼r | Protokol | GerÃ§ek DÃ¼nya SenaryolarÄ± |
| :--- | :--- | :--- |
| **Block Storage** | **RBD** | â€¢ Sanal Makineler (Proxmox, VMware, OpenStack)<br>â€¢ Kubernetes StatefulSets (PostgreSQL, Kafka)<br>â€¢ Fiziksel sunuculara ek disk (iSCSI/RBD) |
| **File Storage** | **CephFS** | â€¢ Ortak Ã§alÄ±ÅŸma alanlarÄ± (Departman paylaÅŸÄ±mlarÄ±)<br>â€¢ Medya iÅŸleme (Render farm)<br>â€¢ Log toplama (ELK Stack)<br>â€¢ HPC Cluster'larÄ± |
| **Object Storage** | **RGW (S3)** | â€¢ Yedekleme (Veeam, Restic)<br>â€¢ Statik Web Ä°Ã§eriÄŸi (CDN Origin)<br>â€¢ Big Data (Spark/Hadoop)<br>â€¢ ArÅŸiv (WORM) |

### ğŸ…±ï¸ SektÃ¶rel KullanÄ±m Ã–rnekleri

1. **Bulut SaÄŸlayÄ±cÄ±lar & ISP:**
    * *KullanÄ±m:* IaaS altyapÄ±sÄ±nda mÃ¼ÅŸterilere disk satmak.
    * *Neden:* Multi-tenant yapÄ± ve izolasyon yeteneÄŸi.

2. **Finans & BankacÄ±lÄ±k:**
    * *KullanÄ±m:* DeÄŸiÅŸtirilemez yedekler (Immutable Backup).
    * *Neden:* S3 Object Lock (WORM) ile yasal uyumluluk ve Ransomware korumasÄ±.

3. **Medya & EÄŸlence:**
    * *KullanÄ±m:* 4K/8K video dÃ¼zenleme havuzu.
    * *Neden:* CephFS ile yÃ¼zlerce editÃ¶rÃ¼n aynÄ± anda ham gÃ¶rÃ¼ntÃ¼lere eriÅŸebilmesi.

4. **Kamu & GÃ¼venlik:**
    * *KullanÄ±m:* MOBESE / GÃ¼venlik kamerasÄ± kayÄ±tlarÄ±.
    * *Neden:* Petabyte Ã¶lÃ§eÄŸinde maliyet etkin depolama.

### ğŸŒ Modern Trendler (2024-2026)

* **Kubernetes-First:** Rook operatÃ¶rÃ¼ ile Ceph'in tamamen K8s iÃ§inde yÃ¶netilmesi.
* **Edge Computing:** Åubelerde kÃ¼Ã§Ã¼k Ceph cluster'larÄ±, merkezde devasa cluster (Replikasyon ile).
* **AI/ML Pipeline:** EÄŸitim verisetlerinin CephFS Ã¼zerinden GPU sunucularÄ±na beslenmesi.
* **Green Storage:** Erasure Coding (EC) kullanÄ±mÄ±yla %50 enerji tasarrufu.

### âš ï¸ Ceph Nerede KULLANILMAMALI?

Ceph "her derde deva" deÄŸildir. Åu senaryolarda geleneksel Ã§Ã¶zÃ¼mler daha iyidir:

* **âŒ Ultra-DÃ¼ÅŸÃ¼k Gecikme (HFT):** YÃ¼ksek frekanslÄ± borsa iÅŸlemleri gibi *mikrosaniye* hassasiyeti gereken yerler (NVMe-oF veya local disk kullanÄ±n).
* **âŒ Mikro Kurulumlar:** Sadece 2-3 sunucu ve basit dosya paylaÅŸÄ±mÄ± iÃ§in Ceph'in bakÄ±m yÃ¼kÃ¼ne deÄŸmez (TrueNAS/Samba kullanÄ±n).
* **âŒ Windows-Native Ortamlar:** EÄŸer %100 Windows ve Active Directory odaklÄ±ysanÄ±z, SMB desteÄŸi iÃ§in ek katmanlar gerekir (Native Windows Server daha az baÅŸ aÄŸrÄ±tÄ±r).

### 6ï¸âƒ£ Ã–zet: "Herkesin Verisi Tek Yerde"

## 8. Ã–zet

Ceph, donanÄ±m baÄŸÄ±msÄ±zlÄ±ÄŸÄ± sunan, kendi kendini yÃ¶netebilen ve iyileÅŸtirebilen **"GeleceÄŸin Depolama teknolojisidir"**. Ã–ÄŸrenme eÄŸrisi diktir (zordur), ancak bir kez kavradÄ±ÄŸÄ±nÄ±zda veri merkezinizin en gÃ¼venilir parÃ§asÄ± olur. DonanÄ±m bozulur, diskler yanar, sunucular Ã§Ã¶ker; ama **Ceph hayatta kalÄ±r.**

> **SÄ±radaki AdÄ±m:** Teori bittiyse, gerÃ§ek hayatta nasÄ±l kullanacaÄŸÄ±nÄ±zÄ± gÃ¶rmek iÃ§in **[14-ceph-scenario-cookbook.md](14-ceph-scenario-cookbook.md)** dosyasÄ±ndaki 14 FarklÄ± Senaryoyu inceleyin.
