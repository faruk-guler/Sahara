# ğŸŒªï¸ Ceph Disaster Recovery (DR) & Backup Stratejisi

Bu dokÃ¼man, "her ÅŸeyin ters gittiÄŸi" senaryolar iÃ§indir. Standart operasyonlarÄ±n dÄ±ÅŸÄ±nda, **veri kaybÄ± riski iÃ§eren** ancak hayati kurtarma iÅŸlemlerini (Last Resort) kapsar.

> [!WARNING]
> **YASAL UYARI:** Buradaki komutlar (Ã¶zellikle `ceph-objectstore-tool` ve `monmap` araÃ§larÄ±) yanlÄ±ÅŸ kullanÄ±ldÄ±ÄŸÄ±nda verilerinizi kalÄ±cÄ± olarak yok edebilir. Production ortamÄ±nda uygulamadan Ã¶nce mutlaka yedeklerinizi doÄŸrulayÄ±n.
>
> **Ã–NEMLÄ° NOT (Cephadm KullanÄ±cÄ±larÄ±):** Bu dokÃ¼mandaki `ceph-mon`, `ceph-objectstore-tool` gibi dÃ¼ÅŸÃ¼k seviyeli araÃ§lar host iÅŸletim sisteminde yÃ¼klÃ¼ gelmez. Bu komutlarÄ± Ã§alÄ±ÅŸtÄ±rmak iÃ§in ilgili daemon'Ä±n konteynerine girmeniz veya `cephadm shell` kullanmanÄ±z gerekir.
>
> **Container iÃ§ine girmek iÃ§in:**
> `cephadm unit --name mon.node1 --enter`
> veya veri dizinlerini mount ederek shell aÃ§mak iÃ§in:
> `cephadm shell --mount /var/lib/ceph:/var/lib/ceph`

---

## ğŸ’¾ 1. Backup Stratejisi (Yedekleme)

Ceph kendi kendine yedek almaz. Cluster Ã§Ã¶ktÃ¼ÄŸÃ¼nde geri dÃ¶nebilmek iÃ§in ÅŸu 3 ÅŸeyi elinizde tutmalÄ±sÄ±nÄ±z:

1. **Ceph KonfigÃ¼rasyonlarÄ±:** `/etc/ceph/` dizini.
2. **Monitor Database (RocksDB):** Cluster haritasÄ±nÄ±n kalbi.
3. **OSD Keyring'leri:** Diskleri tanÄ±mak iÃ§in.

### A. MON VeritabanÄ± YedeÄŸi

Monitor'ler cluster'Ä±n beynidir. Hepsi Ã¶lÃ¼rse cluster biter. DÃ¼zenli olarak **en az bir MON'un** yedeÄŸini alÄ±n.

```bash
# Servisi durdurmadan yedek almak mÃ¼mkÃ¼n deÄŸildir!
# Ancak RocksDB snapshot Ã¶zelliÄŸi ile canlÄ± yedek alÄ±nabilir (Riskli olabilir).
# En gÃ¼venlisi: Bir MON'u durdurup kopyalamaktÄ±r.

# 1. Klasik YÃ¶ntem (Cold Backup)
systemctl stop ceph-mon@node1
tar -czvf mon-backup-$(date +%F).tar.gz /var/lib/ceph/mon/ceph-node1
systemctl start ceph-mon@node1
```

### B. KonfigÃ¼rasyon ve Keyring Yedeklemesi

Her node'da deÄŸil, admin node'da bu betiÄŸi cron'a ekleyin:

```bash
#!/bin/bash
BACKUP_DIR="/backup/ceph-config"
mkdir -p $BACKUP_DIR
tar -czvf $BACKUP_DIR/ceph-etc-$(date +%F).tar.gz /etc/ceph
```

---

## ğŸ§  2. Monitor Recovery (Quorum KaybÄ±)

**Senaryo:** Elektrik kesintisi oldu, diskler yandÄ± ve 3 MON'dan 3'Ã¼ de aÃ§Ä±lmÄ±yor veya veritabanlarÄ± bozuldu (Corrupted). Cluster cevap vermiyor.

**Ã‡Ã¶zÃ¼m:** Elimizde kalan en son Ã§alÄ±ÅŸan MON verisini bulup tek bir MON ile cluster'Ä± zorla ayaÄŸa kaldÄ±rmak.

### AdÄ±m 1: Monmap'i Ã‡Ä±kar

Bozuk olan ama diski saÄŸlam MON sunucusuna girin:

```bash
# MON servisini durdur
systemctl stop ceph-mon@node1

# O anki monmap'i dÄ±ÅŸarÄ± aktar (Konteyner iÃ§inde veya cephadm shell ile)
# YÃ¶ntem 1: Container iÃ§ine girerek (Ã–nerilen)
cephadm unit --name mon.node1 --enter

# Ä°Ã§eride komutu Ã§alÄ±ÅŸtÄ±r:
ceph-mon -i node1 --extract-monmap /tmp/monmap
exit

# YÃ¶ntem 2: DÄ±ÅŸarÄ±dan Ã§alÄ±ÅŸtÄ±rma (Host Ã¼zerinden)
cephadm shell --name mon.node1 -- fsid=$(ceph fsid) -- ceph-mon -i node1 --extract-monmap /tmp/monmap
```

### AdÄ±m 2: Monmap'i DÃ¼zenle

Cluster'Ä± tek MON ile (mesela node1 ile) kandÄ±rarak aÃ§acaÄŸÄ±z.

```bash
# Monmap'i gÃ¶rÃ¼ntÃ¼le
monmaptool --print /tmp/monmap

# DiÄŸer bozuk MON'larÄ± listeden sil (node2 ve node3'Ã¼ siliyoruz)
monmaptool --rm node2 --rm node3 /tmp/monmap

# Tek kalan MON'u "inject" ediyoruz
# (Monmap dosyasÄ±nÄ± container'Ä±n gÃ¶rebileceÄŸi bir yere taÅŸÄ±dÄ±ÄŸÄ±nÄ±zdan emin olun)
cephadm unit --name mon.node1 --enter
ceph-mon -i node1 --inject-monmap /tmp/monmap
```

### AdÄ±m 3: Cluster'Ä± BaÅŸlat

```bash
systemctl start ceph-mon@node1
ceph -s
# Cluster "HEALTH_WARN" ile gelmeli. Sonra diÄŸer MON'larÄ± sÄ±fÄ±rdan ekleyebilirsiniz.
```

---

## ğŸ› ï¸ 3. OSD Recovery (ceph-objectstore-tool)

**Senaryo:** Bir OSD `down` oldu ve tekrar `up` olmuyor. Ä°Ã§indeki verileri kurtarÄ±p baÅŸka yere taÅŸÄ±mamÄ±z lazÄ±m ama disk mount edilemiyor Ã§Ã¼nkÃ¼ BlueStore kullanÄ±yor.

**Ã‡Ã¶zÃ¼m:** `ceph-objectstore-tool` kullanarak ham veriyi dÄ±ÅŸarÄ± Ã§ekmek.

### AdÄ±m 1: Bozuk OSD'yi HazÄ±rla

```bash
systemctl stop ceph-osd@5
```

### AdÄ±m 2: Veri TutarlÄ±lÄ±ÄŸÄ±nÄ± Kontrol Et (FSCK)

```bash
# Deep fsck (Container iÃ§inde)
# Ã–nce OSD container'Ä±na girin veya shell aÃ§Ä±n
cephadm unit --name osd.5 --enter

# Container iÃ§inde:
ceph-objectstore-tool --data-path /var/lib/ceph/osd/ceph-5 \
  --op fsck \
  --type bluestore
```

### AdÄ±m 3: PG (Placement Group) DÄ±ÅŸa Aktarma

Diyelim ki `2.5f` numaralÄ± PG'de kritik verin var.

```bash
# PG'yi dosyaya yedekle
ceph-objectstore-tool --data-path /var/lib/ceph/osd/ceph-5 \
  --pgid 2.5f \
  --op export \
  --file /tmp/pg-2.5f.export

# BaÅŸka bir (saÄŸlam) OSD'ye import et (Ã–rn: OSD 6)
ceph-objectstore-tool --data-path /var/lib/ceph/osd/ceph-6 \
  --op import \
  --file /tmp/pg-2.5f.export
```

### AdÄ±m 4: Tek Bir Objeyi (DosyayÄ±) Kurtarmak

```bash
# Objeyi listele
ceph-objectstore-tool --data-path /var/lib/ceph/osd/ceph-5 --op list

# Objeyi dÄ±ÅŸarÄ± al (extract)
ceph-objectstore-tool --data-path /var/lib/ceph/osd/ceph-5 \
  --pgid 2.5f \
  '{"oid":"myobject","key":"","snapid":-2,"hash":...}' \
  get-bytes > /tmp/kurtarilan_dosya
```

---

## ğŸ—„ï¸ 4. Metadata HasarÄ± (CephFS & RGW)

### CephFS Journal Recovery

MDS sunucularÄ± Ã§Ã¶ktÃ¼ ve dosya sistemi mount edilemiyorsa:

```bash
# Journal'Ä± sÄ±fÄ±rla (Veri kaybÄ± olabilir, sadece metadata dÃ¼zelir)
cephfs-journal-tool --rank=myfs:0 journal reset

# Metadata tablosunu tarayÄ±p onar
cephfs-table-tool myfs:0 reset session
cephfs-table-tool myfs:0 reset snap
cephfs-table-tool myfs:0 reset inode
```

### RGW Index Senkronizasyonu

S3 bucket listelemede dosya var ama indirince yok diyor veya tam tersi (Index mismatch).

```bash
# Bucket index'ini kontrol et
radosgw-admin bucket check --bucket=mybucket

# Index'i onar
radosgw-admin bucket check --fix --bucket=mybucket

# Ciddi durumlarda index'i silip yeniden oluÅŸtur
radosgw-admin bucket rm --bucket=mybucket --bypass-gc
# (Dikkat: Bucket boÅŸ deÄŸilse objects kalÄ±r ama orphan olur)
```

---

## â˜ ï¸ 5. "Data Lost" Ä°lan Etme (Nuclear Option)

EÄŸer diskler fiziksel olarak yandÄ±ysa ve replikalar yetersizse (min_size altÄ±na dÃ¼ÅŸÃ¼ldÃ¼yse), cluster G/Ã‡ iÅŸlemlerini durdurur. Ä°ÅŸlemleri devam ettirmek iÃ§in "Veriyi kaybettim, devam et" demeniz gerekir.

**Bu iÅŸlem veriyi geri getirmez, sadece cluster'Ä±n takÄ±lmasÄ±nÄ± engeller.**

```bash
# 1. HatalÄ± PG'leri bul
ceph pg dump_stuck

# 2. PG'yi "lost" olarak iÅŸaretle
# EÄŸer PG komple kayÄ±psa:
ceph pg 2.5f mark_unfound_lost delete

# Veya eski versiyona dÃ¶n (Revert)
ceph pg 2.5f mark_unfound_lost revert
```

---

## ğŸ“œ 6. DR Checklist (Afet AnÄ±nda YapÄ±lacaklar)

1. **Sakin Ol:** Panikle komut girmek daha bÃ¼yÃ¼k felakete yol aÃ§ar.
2. **Durumu Anla:** `ceph -s`, `ceph health detail`, `dmesg` Ã§Ä±ktÄ±larÄ±na bak.
3. **DonanÄ±mÄ± Kontrol Et:** Diskler fiziksel olarak dÃ¶nÃ¼yor mu? AÄŸ kablosu takÄ±lÄ± mÄ±?
4. **Noout Koy:** `ceph osd set noout` ile cluster'Ä±n gereksiz rebalance yapmasÄ±nÄ± engelle.
5. **LoglarÄ± Oku:** `/var/log/ceph/` altÄ±ndaki loglarda "panic", "segfault" ara.
6. **IRC/Mailing List:** Ã‡Ã¶zemiyorsan Ceph topluluÄŸuna (ceph-users) loglarla sor.
